# Week 5: 분류

Classification

Lecture Session 1:

1. 분류 문제 개요 (Overview of Classification Problems)
2. k-최근접 이웃 (k-Nearest Neighbors)
3. 의사결정나무 (Decision Trees)
4. 나이브 베이즈 분류 (Naive Bayes Classification)
5. 서포트 벡터 머신 (Support Vector Machines)

Lecture Session 2:

1. 앙상블 기법: 배깅, 부스팅, 스태킹 (Ensemble Methods: Bagging, Boosting, and Stacking)
2. 랜덤 포레스트 (Random Forests)
3. 그래디언트 부스팅 (Gradient Boosting)
4. 분류 모델 성능 지표 (Classification Model Performance Metrics)
5. 분류 모델 선택 및 최적화 (Classification Model Selection and Optimization)

Lab Session:

1. k-최근접 이웃 분류 실습 (Hands-on k-Nearest Neighbors Classification)
2. 의사결정나무 분류 실습 (Hands-on Decision Trees Classification)
3. 나이브 베이즈 분류 실습 (Hands-on Naive Bayes Classification)
4. 서포트 벡터 머신 분류 실습 (Hands-on Support Vector Machines Classification)
5. 앙상블 기법 및 고급 분류 기법 실습 (Hands-on Ensemble and Advanced Classification Techniques)

```{tableofcontents}

```
