# 머신러닝 모델의 학습과 평가

## 지도 학습 (Supervised Learning)

### 지도 학습의 정의 및 기본 원리

```{image} figs/image-2-2-1.jpeg
:width: 60%
:align: center
```

- **정의**: 지도 학습은 입력 데이터와 그에 해당하는 출력(레이블)을 사용하여 모델을 훈련시키는 방법
- **기본 원리**: 입력 데이터와 레이블 쌍을 모델에 제공하여, 새로운 데이터에 대한 예측을 수행
- **학습 과정**: 미리 레이블링된 데이터셋을 사용하여 알고리즘이 패턴을 학습하고, 이를 기반으로 결정 또는 예측

### 분류(Classification)와 회귀(Regression)의 개념

```{image} figs/image-2-2-2.jpeg
:width: 60%
:align: center
```

- **분류(Classification)**:
  - 데이터를 미리 정의된 여러 클래스 중 하나로 분류
  - 예: 이메일이 스팸인지 아닌지 분류(이항 분류), 손글씨 숫자 인식(다항 분류)
- **회귀(Regression)**:
  - 연속적인 값을 예측하는 방법
  - 예: 주택 가격 예측, 온도 예측 등

### 지도 학습의 대표적인 알고리즘

```{image} figs/image-2-2-3.jpeg
:width: 60%
:align: center
```

- **Naive Bayes 분류기**:
  - 조건부 확률을 이용하여 분류하는 간단하고 효율적인 방법
  - 스팸 메일 분류, 문서 분류 등에 적합
- **의사결정 트리(Decision Tree)**:
  - 데이터를 기반으로 결정 노드와 잎 노드로 구성된 트리 구조를 생성
  - 결정 규칙을 명확하게 시각화 가능
- **SVM(Support Vector Machine)**:
  - 데이터를 가장 잘 구분하는 경계를 찾는 알고리즘
  - 마진의 최대화를 통해 데이터를 분류

### 지도 학습의 장단점

```{image} figs/image-2-2-4.jpeg
:width: 60%
:align: center
```

- **장점**:
  - 높은 정확도와 신뢰성
  - 다양한 실제 문제에 적용 가능
  - 결과의 해석이 비교적 쉬움
- **단점**:
  - 고품질의 레이블링된 데이터 필요
  - 과적합(Overfitting)의 위험
  - 레이블이 없는 데이터에는 적용 불가

## 비지도 학습 (Unsupervised Learning)

### 비지도 학습의 정의 및 핵심 개념

```{image} figs/image-2-3-1.jpeg
:width: 60%
:align: center
```

- **정의**: 레이블이나 분류가 없는 데이터를 분석하여 패턴, 구조, 관계 등을 찾아내는 학습 방법
- **핵심 개념**: 입력 데이터만을 사용하여 데이터의 숨겨진 특성이나 구조를 발견
- **목적**: 데이터의 내재된 구조를 이해하거나 새로운 통찰력을 얻는 것

### 클러스터링(Clustering)과 차원 축소(Dimensionality Reduction) 이해

```{image} figs/image-2-3-2.jpeg
:width: 60%
:align: center
```

- **클러스터링(Clustering)**:
  - 유사한 특성을 가진 데이터 포인트들을 그룹화
  - 예: 고객 세분화, 사회적 네트워크 분석
- **차원 축소(Dimensionality Reduction)**:
  - 고차원 데이터를 저차원으로 표현하여 복잡성 감소
  - 예: 시각화, 노이즈 제거, 효율적인 저장 및 계산

### 비지도 학습의 대표적인 알고리즘 소개

```{image} figs/image-2-3-3.jpeg
:width: 60%
:align: center
```

- **K-means 클러스터링**:
  - 데이터 포인트를 K개의 클러스터로 그룹화
  - 각 클러스터의 중심을 계산하고 데이터 포인트를 가장 가까운 클러스터에 할당
- **가우스 혼합 모델(Gaussian Mixture Models)**:
  - 데이터가 여러 개의 가우스 분포의 혼합으로 구성됨을 가정
  - 데이터 포인트가 각 가우스 분포에 속할 확률을 계산하여 클러스터링 수행

### 비지도 학습의 장단점 및 도전 과제

```{image} figs/image-2-3-4.jpeg
:width: 60%
:align: center
```

- **장점**:
  - 레이블링 되지 않은 데이터로도 학습 가능
  - 데이터의 숨겨진 특성을 발견할 수 있음
- **단점**:
  - 결과의 해석이 주관적일 수 있음
  - 최적의 결과를 얻기 위한 적절한 파라미터 설정이 필요
- **도전 과제**:
  - 최적의 클러스터 수 결정
  - 고차원 데이터에 대한 효과적인 처리

### 비지도 학습 vs 지도 학습

```{image} figs/image-2-3-5.jpeg
:width: 60%
:align: center
```

| 기준            | 지도 학습 (Supervised Learning)                               | 비지도 학습 (Unsupervised Learning)                                            |
| --------------- | ------------------------------------------------------------- | ------------------------------------------------------------------------------ |
| **입력 데이터** | 입력 (예: 이미지) 및 출력 (예: 레이블)이 명확히 지정된 데이터 | 출력이나 레이블 없이, 오직 입력 데이터만을 사용 (예: 고객 구매 데이터)         |
| **주요 용도**   | 분류 (예: 이메일 스팸 여부 판단), 회귀 (예: 집 가격 예측)     | 클러스터링 (예: 고객 세분화), 차원 축소, 연관 규칙 학습 (예: 시장 바구니 분석) |
| **계산 복잡성** | 데이터 레이블링 필요, 알고리즘 복잡성은 다양                  | 레이블 없이 패턴 인식에 중점, 일부 알고리즘은 매우 복잡                        |
| **성능 평가**   | 명확한 정답이 있으므로 정확도, 정밀도 등으로 평가             | 명확한 정답이 없으므로 평가가 어렵고, 주로 결과의 해석에 의존                  |
| **적용 예시**   | 이미지 인식, 음성 인식, 이메일 필터링                         | 고객 세분화, 추천 시스템, 사회 네트워크 분석                                   |

## 강화 학습 (Reinforcement Learning)

### 강화 학습의 기본 개념과 메커니즘

```{image} figs/image-2-4-1.jpeg
:width: 60%
:align: center
```

- **기본 개념**: 에이전트가 환경과 상호작용하며 보상을 최대화하는 방법을 학습하는 과정
- **메커니즘**: 에이전트가 행동을 취하고, 그 결과로 환경에서 보상 또는 피드백을 받음
- **학습 목표**: 장기적인 관점에서 최대의 보상을 얻을 수 있는 전략(정책)을 학습

### 보상 시스템과 환경의 역할

```{image} figs/image-2-4-2.jpeg
:width: 60%
:align: center
```

- **보상 시스템**: 에이전트의 행동에 따라 긍정적 또는 부정적인 보상을 제공
- **환경**: 에이전트가 상호작용하는 동적인 세계를 의미
- **학습 과정**: 에이전트는 보상을 기반으로 행동을 조정하여 성능을 개선

### 강화 학습의 대표적인 알고리즘 및 응용 예시

```{image} figs/image-2-4-3.jpeg
:width: 60%
:align: center
```

- **알고리즘**:
  - Q-러닝: 행동의 가치를 추정하는 방법
  - 정책 기반 방법: 최적의 행동 정책을 직접 학습
- **응용 예시**:
  - 게임: 체스, 바둑에서 최적의 수 찾기
  - 자율주행: 차량이 다양한 교통 상황에 대응하는 방법 학습

### 게임, 로봇공학, 자율주행 차량 등에서의 강화 학습 활용

```{image} figs/image-2-4-4.jpeg
:width: 60%
:align: center
```

- **게임**: 인공지능이 스스로 게임을 플레이하며 전략을 개발
- **로봇공학**: 로봇이 환경에 적응하고 특정 작업을 수행하는 방법 학습
- **자율주행 차량**: 실시간으로 변화하는 도로 상황에 대응하는 전략 학습

### 강화 학습의 현재 연구 동향 및 미래 가능성

```{image} figs/image-2-4-5.jpeg
:width: 60%
:align: center
```

- **연구 동향**: 복잡한 환경에서의 학습, 다중 에이전트 시스템, 실시간 학습
- **미래 가능성**: 고도화된 의사결정 시스템, 스마트한 자동화 솔루션
- **사회적 영향**: 교육, 의료, 산업 등 다양한 분야에서의 응용 가능성

## 머신러닝 학습 방법의 선택과 적용

### 특정 문제에 적합한 학습 방법 결정하기

```{image} figs/image-2-5-1.jpeg
:width: 60%
:align: center
```

- **문제의 성격 파악**: 분류, 회귀, 클러스터링, 강화 학습 중 어떤 문제인가?
- **지도 학습과 비지도 학습의 구분**: 레이블이 있는 데이터인지 여부를 고려
- **복잡도와 정확도**: 문제의 복잡도에 따른 적합한 알고리즘 선택
- **시간과 자원**: 학습에 소요되는 시간과 필요한 자원 고려

### 데이터의 종류와 양에 따른 학습 방법의 선택

```{image} figs/image-2-5-2.jpeg
:width: 60%
:align: center
```

- **데이터 크기**: 대용량 데이터는 더 강력한 알고리즘 필요
- **데이터 특성**: 텍스트, 이미지, 숫자 등 데이터 유형에 따른 최적의 접근법 선택
- **데이터 품질**: 노이즈가 많거나 불완전한 데이터는 전처리의 중요성

### 머신러닝 모델의 성능 평가 방법

```{image} figs/image-2-5-3.jpeg
:width: 60%
:align: center
```

- **정확도와 오류율**: 모델의 예측 정확도 평가
- **교차 검증**: 데이터의 여러 부분을 사용하여 모델 검증
- **성능 지표**: 정밀도, 재현율, F1 점수 등 다양한 성능 지표 사용

### 머신러닝 프로젝트의 성공적인 구현을 위한 전략 및 팁

```{image} figs/image-2-5-4.jpeg
:width: 60%
:align: center
```

- **적절한 데이터 준비**: 데이터의 질과 양에 주의
- **반복적인 실험**: 다양한 모델과 매개변수로 실험
- **성능 튜닝**: 하이퍼파라미터 조정을 통한 성능 최적화
- **결과 해석과 공유**: 결과 해석의 중요성과 팀 내 공유

## 머신러닝 모델 최적화의 기초

### 목표와 개요

```{image} figs/image-3-1-1.jpeg
:width: 60%
:align: center
```

- **목표**: 모델의 예측 성능 극대화
- **중요성**: 데이터 패턴 이해 증진 및 실제 복잡한 문제 해결

### 선형 회귀 모델의 기본 개념

```{image} figs/image-3-1-2.jpeg
:width: 60%
:align: center
```

- **정의**: 데이터 관계를 직선(y = ax + b)으로 모델링
  - **y**: 종속 변수
  - **x**: 독립 변수
  - **a**: 기울기
  - **b**: y절편
- **목적**: 데이터 포인트에 가장 잘 맞는 직선 찾기

### 최소 제곱법 소개

```{image} figs/image-3-1-3.jpeg
:width: 60%
:align: center
```

- **개념**: 선형 회귀의 매개변수 a, b 찾는 방법
- **원리**: 데이터 포인트와 선형 모델 간 거리(오차)의 제곱 최소화
- **수학적 접근**: 오차 제곱 합 최소화를 통한 최적 매개변수 도출

### 평균 제곱 오차(MSE) 이해

```{image} figs/image-3-1-4.jpeg
:width: 60%
:align: center
```

- **정의**: 예측값과 실제값 간 차이의 수치화
- **계산식**: MSE = (1/n) Σ(actual - prediction)²
- **중요성**: 모델 성능 평가 및 비교의 핵심 지표

## 비용함수와 손실함수

### 비용함수와 손실함수의 정의

```{image} figs/image-3-2-1.jpeg
:width: 60%
:align: center
```

- **정의**:
  - 손실함수(Loss Function): 개별 데이터 포인트에 대한 모델의 오차를 측정
  - 비용함수(Cost Function): 전체 데이터셋에 대한 모델의 성능을 측정
- **중요성**:
  - 이 함수들은 모델이 얼마나 잘 또는 잘못 예측하는지를 나타내며, 이를 최소화하는 것이 모델 학습의 목표

### 평균제곱오차의 역할

```{image} figs/image-3-2-2.jpeg
:width: 60%
:align: center
```

- **평균 제곱 오차(Mean Squared Error, MSE)**:
  - MSE = (1/n) Σ(actual - prediction)²
  - 여기서 Σ는 합계, n은 샘플 수, actual은 실제 값, prediction은 예측값
- **역할**:
  - MSE는 회귀 문제에서 자주 사용되는 손실 함수
  - 모델의 예측과 실제 값 사이의 거리를 제곱하여 평균을 낸 오차의 크기

### 오차 함수와 목적 함수의 비교

```{image} figs/image-3-2-3.jpeg
:width: 60%
:align: center
```

- **오차 함수(Error Function)**:
  - 개별 예측값과 실제값의 차이를 측정
  - 주로 손실 함수로 사용되며, 모델이 개별 데이터 포인트에서 얼마나 잘못 예측하는지를 나타냄
- **목적 함수(Objective Function)**:
  - 전체 데이터셋을 기반으로 한 모델의 전반적인 성능을 측정
  - 비용 함수와 같은 의미로 사용되며, 모델의 성능 최적화를 위한 목표를 설정
- **차이점**:
  - 오차 함수는 개별 데이터 포인트에 초점을 맞추고, 목적 함수는 전체 데이터셋에 대한 성능을 고려

## 경사하강법 (Gradient Descent)

### 경사하강법의 기본 원리

```{image} figs/image-3-3-1.jpeg
:width: 60%
:align: center
```

- **기본 개념**:
  - 경사하강법은 비용 함수의 최소점을 찾기 위한 반복적인 최적화 기법
  - 기울기(gradient)를 사용하여 각 단계에서 비용 함수를 줄여나가는 방식
- **작동 원리**:
  - 현재 위치에서 비용 함수의 기울기를 계산하고, 이를 통해 비용이 감소하는 방향으로 이동
  - 학습률(learning rate)은 이동 거리를 조절하는 파라미터로, 적절한 크기 설정이 중요

### 경사하강법의 다양한 변형

```{image} figs/image-3-3-2.jpeg
:width: 60%
:align: center
```

- **SGD (Stochastic Gradient Descent)**:
  - 매 반복에서 하나의 훈련 샘플을 사용하여 기울기를 계산
  - 빠른 계산이 가능하지만, 비용 함수의 변동이 클 수 있고, 최적의 해를 찾기 어려움
- **Momentum**:
  - 이전 단계의 기울기를 고려하여 관성의 개념을 도입
  - 이를 통해 더 안정적이고 빠르게 최소점에 도달할 수 있음
- **AdaGrad, RMSprop, Adam**:
  - 이 방법들은 학습률을 동적으로 조절하여 더 효율적인 최적화를 달성
  - 각각의 방법은 다른 방식으로 학습률을 조정

### 경사하강법 시각화

```{image} figs/image-3-3-3.jpeg
:width: 60%
:align: center
```

- **비용함수의 모양과 경로**:
  - 비용함수의 모양은 고차원이지만, 일반적으로 2D 또는 3D로 시각화하여 경사하강법의 경로를 이해
  - 시각화는 비용함수의 기울기와 학습률이 경로에 어떤 영향을 미치는지 보여줌
- **시각적 이해**:
  - 경사하강법의 진행 과정을 그래픽으로 나타내어 비용 함수의 최소점에 도달하는 과정을 시각적으로 이해

## 머신러닝 모델의 일반화

### 과대적합과 과소적합

```{image} figs/image-3-4-1.jpeg
:width: 60%
:align: center
```

- **과대적합(Overfitting)**:
  - 모델이 학습 데이터에 너무 적합되어 새로운 데이터에 대한 예측 성능이 떨어지는 현상
  - 학습 데이터의 노이즈나 비정상적인 패턴까지 학습하는 경우 발생
- **과소적합(Underfitting)**:
  - 모델이 학습 데이터의 패턴을 충분히 학습하지 못해 일반화 성능이 낮은 상태
  - 모델이 너무 단순하거나 학습이 충분히 이루어지지 않은 경우 발생

### 최적화 알고리즘의 중요성

```{image} figs/image-3-4-2.jpeg
:width: 60%
:align: center
```

- **일반화 능력 향상**:
  - 최적화 알고리즘은 모델이 학습 데이터뿐만 아니라 새로운 데이터에도 잘 작동하도록 도와줌
  - 모델의 일반화 능력을 향상시켜 실제 세계의 다양한 데이터에 적용 가능하게 함
- **적절한 모델 복잡도**:
  - 최적화를 통해 모델의 복잡도를 조절하고, 과대적합과 과소적합 사이의 균형을 맞춤

### 과대적합과 과소적합 방지 전략

```{image} figs/image-3-4-3.jpeg
:width: 60%
:align: center
```

- **데이터 증강(Data Augmentation)**:
  - 기존 데이터에 변형을 가해 데이터셋의 다양성을 증가시키는 방법
  - 과대적합을 방지하고 모델의 일반화 능력을 향상시킴
- **교차 검증(Cross-Validation)**:
  - 학습 데이터를 여러 부분으로 나누고, 이들을 교차하여 검증하는 방법
  - 모델의 성능을 보다 객관적으로 평가할 수 있음
- **정규화(Regularization)**:
  - 모델의 가중치에 제약을 두어 복잡도를 감소시키는 기술
  - L1, L2 정규화 등이 있으며, 과대적합을 방지하는 데 효과적임

## 좋은 머신러닝 모델의 조건

### 데이터의 양과 질의 중요성

```{image} figs/image-3-5-1.jpeg
:width: 60%
:align: center
```

- **데이터의 중요성**:
  - 머신러닝 모델의 성능은 사용하는 데이터의 양과 질에 크게 의존
  - 충분하고 다양한 데이터는 모델이 더 많은 패턴과 상황을 학습하게 함
- **고품질 데이터의 특성**:
  - 정확하고, 완전하며, 관련성이 높은 데이터
  - 노이즈가 적고, 편향되지 않은 데이터 셋

### 모델 복잡도 조절

```{image} figs/image-3-5-2.jpeg
:width: 60%
:align: center
```

- **모델 복잡도의 중요성**:
  - 모델이 너무 복잡하면 과대적합의 위험이 있고, 너무 단순하면 과소적합이 발생할 수 있음
- **PCA (주성분 분석)**:
  - 고차원 데이터의 차원을 축소하여 모델의 복잡도를 줄이는 기법
  - 중요한 정보를 유지하면서 데이터의 특성 수를 감소시킴

### 일반화, 정규화, 가중치 규제

```{image} figs/image-3-5-3.jpeg
:width: 60%
:align: center
```

- **일반화(Generalization)**:
  - 모델이 새로운 데이터에 대해 잘 예측하는 능력
  - 학습 데이터뿐만 아니라 테스트 데이터에서도 좋은 성능을 나타냄을 의미
- **정규화(Regularization)**:
  - L1, L2 정규화와 같은 기법을 사용하여 모델의 과대적합을 방지
  - 모델의 가중치에 제약을 추가하여 복잡도를 줄임
- **가중치 규제(Weight Regularization)**:
  - 모델의 가중치가 너무 커지지 않도록 제한하여 과대적합을 방지
